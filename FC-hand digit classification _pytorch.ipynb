{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N_g_LXwzo8pc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deifine transformation for the dataset - converting images to tensor and normalizing them\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5))   #Normaliztion with mean std  deviaton\n",
        "])"
      ],
      "metadata": {
        "id": "OAKZCbMJpZWO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST training and test datasets\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train= True,download= True, transform= transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train= False, download = True, transform= transform)"
      ],
      "metadata": {
        "id": "rSgY-Rl7q2LF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4346614-0101-4681-f687-a359f22a5dac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:06<00:00, 4.00MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 260kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.42MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 17.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataloader objects for batching and shuffing the data\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 64, shuffle= True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size = 1000, shuffle= False)"
      ],
      "metadata": {
        "id": "i6T4bw1KuIH4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUgzk5EBXHFv",
        "outputId": "4f32410a-8311-49d9-c907-888266669b5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5,), std=0.5)\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Define the Neural Network model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DEdoGGIwwL6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "# class FashionMNISTModel(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(FashionMNISTModel, self).__init__()\n",
        "#         self.fc1 = nn.Linear(28 * 28, 512)  # Flattened image input (28x28), output 512 nodes\n",
        "#         self.fc2 = nn.Linear(512, 256)      # Hidden layer\n",
        "#         self.fc3 = nn.Linear(256, 10)       # Output layer for 10 classes\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Flatten the input\n",
        "#         x = x.view(x.size(0), -1)  # Flatten to (batch_size, 784)\n",
        "#         x = F.relu(self.fc1(x))    # Apply ReLU after fc1\n",
        "#         x = F.relu(self.fc2(x))    # Apply ReLU after fc2\n",
        "#         x = self.fc3(x)            # Output layer\n",
        "#         return x"
      ],
      "metadata": {
        "id": "PQUoE-pwwuM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModel(nn.Module):\n",
        " def __init__(self):\n",
        "     super(FashionMNISTModel, self).__init__()\n",
        "     self.fc1 = nn.Linear(28 * 28, 512)\n",
        "     self.fc2 = nn.Linear(512, 256)\n",
        "     self.fc3 = nn.Linear(256, 128)\n",
        "     self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        " def forward(self, x):\n",
        "     x = x.view(x.size(0), -1)  # Flatten the input\n",
        "     x = F.relu(self.fc1(x))    # Apply ReLU after fc1\n",
        "    #  x = F.dropout(x, p=0.2)    # Add dropout layer to prevent overfitting\n",
        "     x = F.relu(self.fc2(x))    # Apply ReLU after fc2\n",
        "    #  x = F.dropout(x, p=0.1)    # Add dropout\n",
        "     x = F.relu(self.fc3(x))    # Apply ReLU after fc3\n",
        "     x = self.fc4(x)            # Output layer\n",
        "     return x"
      ],
      "metadata": {
        "id": "fH_6-IWAl0Wz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Model training configuration"
      ],
      "metadata": {
        "id": "a62Kgmv1ajCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, criterion, optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = FashionMNISTModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "metadata": {
        "id": "JFg06iKoYUvs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size = 7, gamma = 0.01)"
      ],
      "metadata": {
        "id": "AaJVmnqPUdUF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,          # The optimizer whose learning rate will be adjusted\n",
        "    mode='min',         # Mode to determine whether the monitored quantity is to be minimized or maximized\n",
        "    factor=0.5,         # Factor by which the learning rate will be reduced\n",
        "    patience=3,         # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    threshold=0.0001,   # Threshold for measuring the new optimum\n",
        "    threshold_mode='rel', # 'rel' means threshold is relative to the best value\n",
        "    cooldown=0,         # Number of epochs to wait before resuming normal operation after lr has been reduced\n",
        "    min_lr=0.00001      # Minimum learning rate\n",
        ")"
      ],
      "metadata": {
        "id": "FjVDhyFe9WIq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()  # Set model to training mode\n",
        "    epoch_loss = 0  # Initialize epoch loss to zero at the start of each epoch\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        output = model(data)   # Forward pass to get output\n",
        "        loss = criterion(output, target)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "        epoch_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch}: Average Loss = {avg_loss:.6f}')\n",
        "\n",
        "        # Print loss every 10 batches\n",
        "        # if batch_idx % 10 == 0:\n",
        "        #     print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]  Loss: {loss.item():.6f}')\n"
      ],
      "metadata": {
        "id": "fbCslLmsfTCq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Trian and Test"
      ],
      "metadata": {
        "id": "drG9Y4lrcCeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # Disable gradient calculation for faster evaluation\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)  # Move data and target to GPU/CPU\n",
        "            output = model(data)  # Forward pass: compute predictions\n",
        "            test_loss += criterion(output, target).item()  # Accumulate loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the predicted class\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # Count correct predictions\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  # Average test loss\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)  # Calculate accuracy\n",
        "\n",
        "    # Print test loss and accuracy\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')"
      ],
      "metadata": {
        "id": "hBArsPRVggdN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50               # Set the number of training epochs\n",
        "\n",
        "for epoch in range(1, n_epochs +1):\n",
        "  train(model,device, train_loader, optimizer, criterion, epoch)      # `train` function is called with the model, device, data loader, optimizer, loss criterion, and current epoch number\n",
        "  test(model, device, test_loader, criterion)\n",
        "  current_lr = optimizer.param_groups[0]['lr']       # Retrieve the current learning rate from the optimizer\n",
        "\n",
        "  print(f'Learning Rate: {current_lr}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9d5WmCzbcnF",
        "outputId": "29bf89b2-760f-4e4e-87c4-4887df86aa20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Average Loss = 0.594029\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8199/10000 (81.99%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 2: Average Loss = 0.471357\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8386/10000 (83.86%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 3: Average Loss = 0.459016\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8314/10000 (83.14%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 4: Average Loss = 0.430889\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8385/10000 (83.85%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 5: Average Loss = 0.428288\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8379/10000 (83.79%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 6: Average Loss = 0.402822\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8426/10000 (84.26%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 7: Average Loss = 0.409874\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8482/10000 (84.82%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 8: Average Loss = 0.407048\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8504/10000 (85.04%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 9: Average Loss = 0.392653\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8301/10000 (83.01%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 10: Average Loss = 0.386740\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8429/10000 (84.29%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 11: Average Loss = 0.389842\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8555/10000 (85.55%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 12: Average Loss = 0.378331\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8490/10000 (84.90%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 13: Average Loss = 0.395587\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8479/10000 (84.79%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 14: Average Loss = 0.378876\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8533/10000 (85.33%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 15: Average Loss = 0.377009\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8482/10000 (84.82%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 16: Average Loss = 0.398405\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8511/10000 (85.11%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 17: Average Loss = 0.368517\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8546/10000 (85.46%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 18: Average Loss = 0.395259\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8524/10000 (85.24%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 19: Average Loss = 0.374977\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8473/10000 (84.73%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 20: Average Loss = 0.362746\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8584/10000 (85.84%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 21: Average Loss = 0.370422\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8504/10000 (85.04%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 22: Average Loss = 0.392637\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8532/10000 (85.32%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 23: Average Loss = 0.376334\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8447/10000 (84.47%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 24: Average Loss = 0.368600\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8557/10000 (85.57%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 25: Average Loss = 0.358736\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8611/10000 (86.11%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 26: Average Loss = 0.365761\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8364/10000 (83.64%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 27: Average Loss = 0.363689\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8583/10000 (85.83%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 28: Average Loss = 0.356080\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8533/10000 (85.33%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 29: Average Loss = 0.384517\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8474/10000 (84.74%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 30: Average Loss = 0.358528\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8515/10000 (85.15%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 31: Average Loss = 0.382151\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8535/10000 (85.35%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 32: Average Loss = 0.355663\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8564/10000 (85.64%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 33: Average Loss = 0.347353\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8560/10000 (85.60%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 34: Average Loss = 0.344661\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8607/10000 (86.07%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 35: Average Loss = 0.360225\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8579/10000 (85.79%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 36: Average Loss = 0.374404\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8498/10000 (84.98%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 37: Average Loss = 0.345618\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8564/10000 (85.64%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 38: Average Loss = 0.382129\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8509/10000 (85.09%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 39: Average Loss = 0.381192\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8483/10000 (84.83%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 40: Average Loss = 0.346298\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8606/10000 (86.06%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 41: Average Loss = 0.379805\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8350/10000 (83.50%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 42: Average Loss = 0.382211\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8403/10000 (84.03%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 43: Average Loss = 0.418490\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8490/10000 (84.90%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 44: Average Loss = 0.356531\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8426/10000 (84.26%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 45: Average Loss = 0.421749\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8432/10000 (84.32%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 46: Average Loss = 0.364126\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8609/10000 (86.09%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 47: Average Loss = 0.364577\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8521/10000 (85.21%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 48: Average Loss = 0.350376\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8629/10000 (86.29%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 49: Average Loss = 0.388134\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 8487/10000 (84.87%)\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Epoch 50: Average Loss = 0.365137\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8515/10000 (85.15%)\n",
            "\n",
            "Learning Rate: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tHj2rlUVaoTk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}